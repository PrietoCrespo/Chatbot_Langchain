{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import initialize_weaviate_and_get_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28bf4f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conectado a Weaviate local\n",
      "üóëÔ∏è Colecci√≥n 'DocumentosPDFOllama' eliminada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jose\\Documents\\Programacion\\Chatbot_Langchain\\.venv\\Lib\\site-packages\\weaviate\\warnings.py:196: DeprecationWarning: Dep024: You are using the `vectorizer_config` argument in `collection.config.create()`, which is deprecated.\n",
      "            Use the `vector_config` argument instead.\n",
      "            \n",
      "  warnings.warn(\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Colecci√≥n 'DocumentosPDFOllama' creada con configuraci√≥n de vector NONE (BYOV - Bring Your Own Vectors)\n",
      "üìù Documento dividido en 21 chunks\n",
      "ü§ñ Generando embeddings con Ollama e insertando documentos...\n",
      "‚úÖ 21 documentos insertados con embeddings de Ollama.\n",
      "‚ú® Retriever de LangChain creado para la colecci√≥n 'DocumentosPDFOllama'\n"
     ]
    }
   ],
   "source": [
    "retriever = initialize_weaviate_and_get_retriever(data_folder='./data',collection_name='DocumentosPDFOllama')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5e30aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jose\\AppData\\Local\\Temp\\ipykernel_1148\\714906086.py:13: ResourceWarning: unclosed <socket.socket fd=1560, family=2, type=1, proto=0, laddr=('127.0.0.1', 53174), raddr=('127.0.0.1', 11434)>\n",
      "  rag_chain = (\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\Users\\Jose\\Documents\\Programacion\\Chatbot_Langchain\\.venv\\Lib\\site-packages\\weaviate\\warnings.py:302: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n",
      "            Please make sure to close the connection using `client.close()`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jose\\AppData\\Local\\Temp\\ipykernel_1148\\714906086.py:13: ResourceWarning: unclosed <socket.socket fd=1300, family=23, type=1, proto=0, laddr=('::1', 53075, 0, 0), raddr=('::1', 8080, 0, 0)>\n",
      "  rag_chain = (\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Jose\\AppData\\Local\\Temp\\ipykernel_1148\\714906086.py:13: ResourceWarning: unclosed <socket.socket fd=1388, family=2, type=1, proto=0, laddr=('127.0.0.1', 53175), raddr=('127.0.0.1', 11434)>\n",
      "  rag_chain = (\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: Quien es velazquez?\n",
      "Respuesta: \n",
      "\n",
      "Diego Vel√°zquez fue un pintor espa√±ol cuyo trabajo se divide en dos etapas: la sevillana (1599-1623) y la madrile√±a. Durante la etapa sevillana, estudi√≥ bajo el maestro Pacheco y realiz√≥ obras en el tenebrismo, caracterizado por el realismo y contraste de luz.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "llm = OllamaLLM(model=\"qwen3:4b\")\n",
    "\n",
    "template = \"\"\"Responde a la pregunta bas√°ndote √∫nicamente en el siguiente contexto:\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Hacemos una pregunta\n",
    "pregunta = \"Quien es velazquez?\"\n",
    "\n",
    "# Invocamos la cadena\n",
    "respuesta = rag_chain.invoke(pregunta).split('</think>')[1]\n",
    "\n",
    "print(f\"Pregunta: {pregunta}\")\n",
    "print(f\"Respuesta: {respuesta}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
